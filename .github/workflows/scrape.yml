name: Scrape AmiAmi Sales

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          wget \
          unzip \
          libnss3 \
          libxss1 \
          libindicator7 \
          libatk-bridge2.0-0 \
          libgtk-3-0 \
          libxi6 \
          libu2f-udev \
          libasound2t64 \
          fonts-liberation

    - name: Install Python dependencies
      run: |
        pip install -r requirements.txt

    - name: Install Playwright browsers
      run: |
        playwright install

    - name: Run Playwright scraper
      run: |
        python amiami-sales.py
        echo "Scraper run complete."
        ls -lh AmiAmi_sales.csv || echo "CSV not found"
        ls -lh AmiAmi_sales.md || echo "md not found"
        git status

    - name: Commit and push CSV
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add AmiAmi_sales.csv
        git add AmiAmi_sales.md
        git commit -m "Auto-update CSV/MD" || echo "No changes to commit"
        git push origin HEAD
